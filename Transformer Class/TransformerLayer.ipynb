{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Transformer (Multi-head Attention Class)\n",
        "EC523 Project\n",
        "Team 2"
      ],
      "metadata": {
        "id": "kTSjywqZMkZd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cqScFtetMhFy"
      },
      "outputs": [],
      "source": [
        "# Import Libraries\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import r2_score\n",
        "from torch.utils.data import DataLoader, TensorDataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformer Class"
      ],
      "metadata": {
        "id": "Tipg3lG2SEAt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, num_heads, output_dim):\n",
        "    super(Transformer, self).__init__()\n",
        "    self.input_dim = input_dim\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.num_heads = num_heads\n",
        "    self.output_dim = output_dim\n",
        "\n",
        "    self.multihead_attn = nn.MultiheadAttention(embed_dim=self.input_dim, num_heads=self.num_heads, batch_first=True)\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "    attn_output, attn_weights = self.multihead_attn(x,x,x)\n",
        "\n",
        "    return attn_output, attn_weights\n"
      ],
      "metadata": {
        "id": "s668EQv6ROZJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate Random X and Y"
      ],
      "metadata": {
        "id": "Yxvc3XcZSb_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Width, Height = 10, 10\n",
        "Images = 30\n",
        "\n",
        "X = np.random.rand(Images, Width, Height).reshape(-1, Width * Height)\n",
        "Y = np.random.rand(Images, Width, Height).reshape(-1, Width * Height)\n",
        "print(f'Shape of Flattened Image:', X.shape)\n",
        "\n",
        "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
        "Y_tensor = torch.tensor(Y, dtype=torch.float32)\n",
        "\n",
        "dataset = TensorDataset(X_tensor, Y_tensor)\n",
        "dataloader = DataLoader(dataset, batch_size=20, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPMySKkOSbP3",
        "outputId": "90d7ad9f-4a52-49ea-af93-7a3d40b78b01"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Flattened Image: (30, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instaniate Class (Parameters)"
      ],
      "metadata": {
        "id": "CnkD15L4TPnn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate Model Class\n",
        "transformer_model = Transformer(input_dim=100, hidden_dim=120, num_heads=4, output_dim=100)\n",
        "\n",
        "# Set Optimizer and Training Loss\n",
        "loss = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(transformer_model.parameters(), lr=0.001)\n",
        "\n",
        "# Training Parameters\n",
        "num_epochs = 100\n",
        "batch_size = 20"
      ],
      "metadata": {
        "id": "bfpb738vTUdp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print Model Parameters\n",
        "for name, param in transformer_model.named_parameters():\n",
        "    print(f\"Parameter name: {name}\")\n",
        "    print(f\"Shape: {param.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58a-8ToIWfeu",
        "outputId": "8bec10ac-16fb-4ff2-80f2-78df71dfa0ba"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter name: multihead_attn.in_proj_weight\n",
            "Shape: torch.Size([300, 100])\n",
            "Parameter name: multihead_attn.in_proj_bias\n",
            "Shape: torch.Size([300])\n",
            "Parameter name: multihead_attn.out_proj.weight\n",
            "Shape: torch.Size([100, 100])\n",
            "Parameter name: multihead_attn.out_proj.bias\n",
            "Shape: torch.Size([100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train Model"
      ],
      "metadata": {
        "id": "NbZPFMOyXKNE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "transformer_model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dc0rLGV2YNhR",
        "outputId": "754ff7ee-5d2d-43fa-f57c-c6ed4de4ac1b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Transformer(\n",
              "  (multihead_attn): MultiheadAttention(\n",
              "    (out_proj): NonDynamicallyQuantizableLinear(in_features=100, out_features=100, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Training\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    transformer_model.train()\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    for batch_idx, (inputs, targets) in enumerate(dataloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        inputs = inputs.view(inputs.size(0), -1, 100)  # Reshape for input_dim=100\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs, _ = transformer_model(inputs)\n",
        "        loss_value = loss(outputs, targets)\n",
        "        loss_value.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss_value.item()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss / len(dataloader):.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbk0DnP6XJvl",
        "outputId": "a8a8256e-c504-4bea-d406-8243ecd721a2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([20, 100])) that is different to the input size (torch.Size([20, 1, 100])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([10, 100])) that is different to the input size (torch.Size([10, 1, 100])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100], Loss: 0.3330\n",
            "Epoch [2/100], Loss: 0.2551\n",
            "Epoch [3/100], Loss: 0.1953\n",
            "Epoch [4/100], Loss: 0.1530\n",
            "Epoch [5/100], Loss: 0.1268\n",
            "Epoch [6/100], Loss: 0.1110\n",
            "Epoch [7/100], Loss: 0.1034\n",
            "Epoch [8/100], Loss: 0.1009\n",
            "Epoch [9/100], Loss: 0.0987\n",
            "Epoch [10/100], Loss: 0.1001\n",
            "Epoch [11/100], Loss: 0.0997\n",
            "Epoch [12/100], Loss: 0.1001\n",
            "Epoch [13/100], Loss: 0.0972\n",
            "Epoch [14/100], Loss: 0.0948\n",
            "Epoch [15/100], Loss: 0.0930\n",
            "Epoch [16/100], Loss: 0.0916\n",
            "Epoch [17/100], Loss: 0.0917\n",
            "Epoch [18/100], Loss: 0.0909\n",
            "Epoch [19/100], Loss: 0.0903\n",
            "Epoch [20/100], Loss: 0.0900\n",
            "Epoch [21/100], Loss: 0.0898\n",
            "Epoch [22/100], Loss: 0.0892\n",
            "Epoch [23/100], Loss: 0.0879\n",
            "Epoch [24/100], Loss: 0.0870\n",
            "Epoch [25/100], Loss: 0.0875\n",
            "Epoch [26/100], Loss: 0.0863\n",
            "Epoch [27/100], Loss: 0.0874\n",
            "Epoch [28/100], Loss: 0.0864\n",
            "Epoch [29/100], Loss: 0.0864\n",
            "Epoch [30/100], Loss: 0.0865\n",
            "Epoch [31/100], Loss: 0.0859\n",
            "Epoch [32/100], Loss: 0.0856\n",
            "Epoch [33/100], Loss: 0.0861\n",
            "Epoch [34/100], Loss: 0.0853\n",
            "Epoch [35/100], Loss: 0.0852\n",
            "Epoch [36/100], Loss: 0.0842\n",
            "Epoch [37/100], Loss: 0.0853\n",
            "Epoch [38/100], Loss: 0.0857\n",
            "Epoch [39/100], Loss: 0.0848\n",
            "Epoch [40/100], Loss: 0.0844\n",
            "Epoch [41/100], Loss: 0.0852\n",
            "Epoch [42/100], Loss: 0.0843\n",
            "Epoch [43/100], Loss: 0.0847\n",
            "Epoch [44/100], Loss: 0.0839\n",
            "Epoch [45/100], Loss: 0.0830\n",
            "Epoch [46/100], Loss: 0.0839\n",
            "Epoch [47/100], Loss: 0.0832\n",
            "Epoch [48/100], Loss: 0.0830\n",
            "Epoch [49/100], Loss: 0.0840\n",
            "Epoch [50/100], Loss: 0.0837\n",
            "Epoch [51/100], Loss: 0.0828\n",
            "Epoch [52/100], Loss: 0.0831\n",
            "Epoch [53/100], Loss: 0.0830\n",
            "Epoch [54/100], Loss: 0.0831\n",
            "Epoch [55/100], Loss: 0.0831\n",
            "Epoch [56/100], Loss: 0.0831\n",
            "Epoch [57/100], Loss: 0.0832\n",
            "Epoch [58/100], Loss: 0.0836\n",
            "Epoch [59/100], Loss: 0.0833\n",
            "Epoch [60/100], Loss: 0.0822\n",
            "Epoch [61/100], Loss: 0.0833\n",
            "Epoch [62/100], Loss: 0.0834\n",
            "Epoch [63/100], Loss: 0.0827\n",
            "Epoch [64/100], Loss: 0.0828\n",
            "Epoch [65/100], Loss: 0.0819\n",
            "Epoch [66/100], Loss: 0.0827\n",
            "Epoch [67/100], Loss: 0.0817\n",
            "Epoch [68/100], Loss: 0.0827\n",
            "Epoch [69/100], Loss: 0.0821\n",
            "Epoch [70/100], Loss: 0.0821\n",
            "Epoch [71/100], Loss: 0.0819\n",
            "Epoch [72/100], Loss: 0.0812\n",
            "Epoch [73/100], Loss: 0.0813\n",
            "Epoch [74/100], Loss: 0.0825\n",
            "Epoch [75/100], Loss: 0.0832\n",
            "Epoch [76/100], Loss: 0.0817\n",
            "Epoch [77/100], Loss: 0.0820\n",
            "Epoch [78/100], Loss: 0.0815\n",
            "Epoch [79/100], Loss: 0.0815\n",
            "Epoch [80/100], Loss: 0.0810\n",
            "Epoch [81/100], Loss: 0.0819\n",
            "Epoch [82/100], Loss: 0.0814\n",
            "Epoch [83/100], Loss: 0.0820\n",
            "Epoch [84/100], Loss: 0.0809\n",
            "Epoch [85/100], Loss: 0.0819\n",
            "Epoch [86/100], Loss: 0.0815\n",
            "Epoch [87/100], Loss: 0.0825\n",
            "Epoch [88/100], Loss: 0.0823\n",
            "Epoch [89/100], Loss: 0.0812\n",
            "Epoch [90/100], Loss: 0.0810\n",
            "Epoch [91/100], Loss: 0.0813\n",
            "Epoch [92/100], Loss: 0.0812\n",
            "Epoch [93/100], Loss: 0.0807\n",
            "Epoch [94/100], Loss: 0.0806\n",
            "Epoch [95/100], Loss: 0.0810\n",
            "Epoch [96/100], Loss: 0.0808\n",
            "Epoch [97/100], Loss: 0.0829\n",
            "Epoch [98/100], Loss: 0.0814\n",
            "Epoch [99/100], Loss: 0.0816\n",
            "Epoch [100/100], Loss: 0.0810\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Testing"
      ],
      "metadata": {
        "id": "180fW2wJY73p"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aN0PYrdzY7nm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}